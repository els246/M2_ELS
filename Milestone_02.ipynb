{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Milestone Two: Modeling and Feature Engineering\n",
    "\n",
    "### Due: Midnight on April 13 (with 2-hour grace period) and worth 25 points\n",
    "\n",
    "### Overview\n",
    "\n",
    "This milestone builds on your work from Milestone 1. You will:\n",
    "\n",
    "1. Evaluate baseline models using default settings.\n",
    "2. Engineer new features and re-evaluate models.\n",
    "3. Use feature selection techniques to find promising subsets.\n",
    "4. Select the top 3 models and fine-tune them for optimal performance.\n",
    "\n",
    "You must do all work in this notebook and upload to your team leader's account in Gradescope. There is no\n",
    "Individual Assessment for this Milestone. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /home/codespace/.python/current/lib/python3.12/site-packages (4.67.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================\n",
    "# Useful Imports: Add more as needed\n",
    "# ===================================\n",
    "\n",
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "import seaborn as sns\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, \n",
    "    cross_val_score, \n",
    "    GridSearchCV, \n",
    "    RandomizedSearchCV, \n",
    "    RepeatedKFold\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "# Progress Tracking\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42\n",
    "\n",
    "# =============================\n",
    "# Utility Functions\n",
    "# =============================\n",
    "\n",
    "# Format y-axis labels as dollars with commas (optional)\n",
    "def dollar_format(x, pos):\n",
    "    return f'${x:,.0f}'\n",
    "\n",
    "# Convert seconds to HH:MM:SS format\n",
    "def format_hms(seconds):\n",
    "    return time.strftime(\"%H:%M:%S\", time.gmtime(seconds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is my change "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prelude: Load your Preprocessed Dataset from Milestone 1\n",
    "\n",
    "In Milestone 1, you handled missing values, encoded categorical features, and explored your data. Before you begin this milestone, you’ll need to load that cleaned dataset and prepare it for modeling.\n",
    "\n",
    "Here’s what to do:\n",
    "\n",
    "1. Return to your Milestone 1 notebook and rerun your code through Part 3, where your dataset was fully cleaned (assume it’s called `df_cleaned`).\n",
    "\n",
    "2. **Save** the cleaned dataset to a file by running:\n",
    "\n",
    ">   df_cleaned.to_csv(\"zillow_cleaned.csv\", index=False)\n",
    "\n",
    "3. Switch to this notebook and **load** the saved data:\n",
    "\n",
    ">   df = pd.read_csv(\"zillow_cleaned.csv\")\n",
    "\n",
    "4. Create a **train/test split** using `train_test_split`.  \n",
    "   \n",
    "6. **Standardize** the features (but not the target!) using **only the training data.** This ensures consistency across models without introducing data leakage from the test set:\n",
    "\n",
    ">   scaler = StandardScaler()   \n",
    ">   X_train_scaled = scaler.fit_transform(X_train)    \n",
    "  \n",
    "**Notes:** \n",
    "\n",
    "- You will not use the testing set during this milestone — it’s reserved for final evaluation later.\n",
    "- You will have to redo the scaling step when you introduce new features (which have to be scaled as well).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       airconditioningtypeid  architecturalstyletypeid   bathroomcnt  \\\n",
      "count           77613.000000              77613.000000  77613.000000   \n",
      "mean                1.812013                  7.386473      2.298496   \n",
      "std                 1.683429                  0.140546      0.996513   \n",
      "min                 1.000000                  2.000000      0.000000   \n",
      "25%                 1.000000                  7.386473      2.000000   \n",
      "50%                 1.812013                  7.386473      2.000000   \n",
      "75%                 1.812013                  7.386473      3.000000   \n",
      "max                13.000000                 21.000000     18.000000   \n",
      "\n",
      "         bedroomcnt  buildingclasstypeid  buildingqualitytypeid  \\\n",
      "count  77613.000000         77613.000000           77613.000000   \n",
      "mean       3.053223             3.933333               6.533779   \n",
      "std        1.140230             0.003468               1.379538   \n",
      "min        0.000000             3.000000               1.000000   \n",
      "25%        2.000000             3.933333               6.000000   \n",
      "50%        3.000000             3.933333               6.533779   \n",
      "75%        4.000000             3.933333               7.000000   \n",
      "max       16.000000             4.000000              12.000000   \n",
      "\n",
      "       calculatedbathnbr  decktypeid  finishedfloor1squarefeet  \\\n",
      "count       77613.000000     77613.0              77613.000000   \n",
      "mean            2.316392        66.0               1366.165314   \n",
      "std             0.975578         0.0                187.042091   \n",
      "min             1.000000        66.0                 44.000000   \n",
      "25%             2.000000        66.0               1366.165314   \n",
      "50%             2.000000        66.0               1366.165314   \n",
      "75%             3.000000        66.0               1366.165314   \n",
      "max            18.000000        66.0               6912.000000   \n",
      "\n",
      "       calculatedfinishedsquarefeet  ...  numberofstories  assessmentyear  \\\n",
      "count                  77613.000000  ...     77613.000000         77613.0   \n",
      "mean                    1784.935421  ...         1.434286          2016.0   \n",
      "std                      952.804598  ...         0.259285             0.0   \n",
      "min                      128.000000  ...         1.000000          2016.0   \n",
      "25%                     1184.000000  ...         1.434286          2016.0   \n",
      "50%                     1546.000000  ...         1.434286          2016.0   \n",
      "75%                     2109.000000  ...         1.434286          2016.0   \n",
      "max                    35640.000000  ...         6.000000          2016.0   \n",
      "\n",
      "       taxdelinquencyyear  taxvaluedollarcnt  mean_propertycountylandusecode  \\\n",
      "count        77613.000000       7.761300e+04                    7.761300e+04   \n",
      "mean            14.088276       4.901506e+05                    4.901506e+05   \n",
      "std              0.421572       6.536504e+05                    1.892402e+05   \n",
      "min              3.000000       1.000000e+03                    1.450000e+05   \n",
      "25%             14.088276       2.069250e+05                    4.021687e+05   \n",
      "50%             14.088276       3.589710e+05                    4.043582e+05   \n",
      "75%             14.088276       5.688620e+05                    5.588589e+05   \n",
      "max             99.000000       4.906124e+07                    8.068454e+06   \n",
      "\n",
      "       mean_propertyzoningdesc  hashottuborspa_True  hashottuborspa_Missing  \\\n",
      "count             7.761300e+04         77613.000000            77613.000000   \n",
      "mean              4.901506e+05             0.019829                0.980171   \n",
      "std               2.877158e+05             0.139414                0.139414   \n",
      "min               3.101800e+04             0.000000                0.000000   \n",
      "25%               3.565037e+05             0.000000                1.000000   \n",
      "50%               5.238313e+05             0.000000                1.000000   \n",
      "75%               5.238313e+05             0.000000                1.000000   \n",
      "max               9.324332e+06             1.000000                1.000000   \n",
      "\n",
      "       taxdelinquencyflag_Missing  taxdelinquencyflag_Y  \n",
      "count                77613.000000          77613.000000  \n",
      "mean                     0.962635              0.037365  \n",
      "std                      0.189655              0.189655  \n",
      "min                      0.000000              0.000000  \n",
      "25%                      1.000000              0.000000  \n",
      "50%                      1.000000              0.000000  \n",
      "75%                      1.000000              0.000000  \n",
      "max                      1.000000              1.000000  \n",
      "\n",
      "[8 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77613 entries, 0 to 77612\n",
      "Data columns (total 50 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   airconditioningtypeid           77613 non-null  float64\n",
      " 1   architecturalstyletypeid        77613 non-null  float64\n",
      " 2   bathroomcnt                     77613 non-null  float64\n",
      " 3   bedroomcnt                      77613 non-null  float64\n",
      " 4   buildingclasstypeid             77613 non-null  float64\n",
      " 5   buildingqualitytypeid           77613 non-null  float64\n",
      " 6   calculatedbathnbr               77613 non-null  float64\n",
      " 7   decktypeid                      77613 non-null  float64\n",
      " 8   finishedfloor1squarefeet        77613 non-null  float64\n",
      " 9   calculatedfinishedsquarefeet    77613 non-null  float64\n",
      " 10  finishedsquarefeet12            77613 non-null  float64\n",
      " 11  finishedsquarefeet13            77613 non-null  float64\n",
      " 12  finishedsquarefeet15            77613 non-null  float64\n",
      " 13  finishedsquarefeet50            77613 non-null  float64\n",
      " 14  finishedsquarefeet6             77613 non-null  float64\n",
      " 15  fips                            77613 non-null  float64\n",
      " 16  fullbathcnt                     77613 non-null  float64\n",
      " 17  garagecarcnt                    77613 non-null  float64\n",
      " 18  garagetotalsqft                 77613 non-null  float64\n",
      " 19  heatingorsystemtypeid           77613 non-null  float64\n",
      " 20  latitude                        77613 non-null  float64\n",
      " 21  longitude                       77613 non-null  float64\n",
      " 22  lotsizesquarefeet               77613 non-null  float64\n",
      " 23  poolcnt                         77613 non-null  float64\n",
      " 24  poolsizesum                     77613 non-null  float64\n",
      " 25  pooltypeid10                    77613 non-null  float64\n",
      " 26  pooltypeid2                     77613 non-null  float64\n",
      " 27  pooltypeid7                     77613 non-null  float64\n",
      " 28  propertylandusetypeid           77613 non-null  float64\n",
      " 29  rawcensustractandblock          77613 non-null  float64\n",
      " 30  regionidcity                    77613 non-null  float64\n",
      " 31  regionidcounty                  77613 non-null  float64\n",
      " 32  regionidneighborhood            77613 non-null  float64\n",
      " 33  regionidzip                     77613 non-null  float64\n",
      " 34  roomcnt                         77613 non-null  float64\n",
      " 35  threequarterbathnbr             77613 non-null  float64\n",
      " 36  typeconstructiontypeid          77613 non-null  float64\n",
      " 37  unitcnt                         77613 non-null  float64\n",
      " 38  yardbuildingsqft26              77613 non-null  float64\n",
      " 39  yearbuilt                       77613 non-null  float64\n",
      " 40  numberofstories                 77613 non-null  float64\n",
      " 41  assessmentyear                  77613 non-null  float64\n",
      " 42  taxdelinquencyyear              77613 non-null  float64\n",
      " 43  taxvaluedollarcnt               77613 non-null  float64\n",
      " 44  mean_propertycountylandusecode  77613 non-null  float64\n",
      " 45  mean_propertyzoningdesc         77613 non-null  float64\n",
      " 46  hashottuborspa_True             77613 non-null  int64  \n",
      " 47  hashottuborspa_Missing          77613 non-null  int64  \n",
      " 48  taxdelinquencyflag_Missing      77613 non-null  int64  \n",
      " 49  taxdelinquencyflag_Y            77613 non-null  int64  \n",
      "dtypes: float64(46), int64(4)\n",
      "memory usage: 29.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv('zillow_cleaned.csv')\n",
    "print(df_cleaned.describe())\n",
    "print(df_cleaned.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_data = df.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# # Impute missing numerical values with the mean and categorical values with the mode\n",
    "# numerical_cols = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "# categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "# # Insert numerical columns with the mean\n",
    "# df[numerical_cols] = df[numerical_cols].fillna(df[numerical_cols].mean())\n",
    "\n",
    "# # Insert categorical columns with the mode\n",
    "# df[categorical_cols].fillna(df[categorical_cols].mode().iloc[0])\n",
    "\n",
    "# # One-Hot Encoding categorical variables\n",
    "# df = pd.get_dummies(df, columns=categorical_cols, drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_cols_1 = ['basementsqft', 'yardbuildingsqft17', 'fireplacecnt', 'storytypeid']\n",
    "\n",
    "# # Drop the columns\n",
    "# df.drop(columns=drop_cols_1, inplace=True)\n",
    "\n",
    "# # Confirm the changes\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop samples with too many null values \n",
    "# threshold = 0.50  #gets rid of rows with over 50% missing values \n",
    "# null_percentage = df.isnull().mean(axis=1)\n",
    "# df_cleaned3c = df[null_percentage < threshold]\n",
    "# #print(df_cleaned3c) #these is the dataframe with dropped samples with na values > 50%\n",
    "\n",
    "# # drop samples with null values in target \n",
    "# df_no_null_target = df_cleaned3c[df_cleaned3c['taxvaluedollarcnt'].notnull()]\n",
    "# #print(df_no_null_target)\n",
    "\n",
    "# #get rid of samples with outliers in target using quartiles\n",
    "# q1 = df_no_null_target['taxvaluedollarcnt'].quantile(0.25)\n",
    "# q3 = df_no_null_target['taxvaluedollarcnt'].quantile(0.75)\n",
    "# IQR = q3 - q1\n",
    "# lower_bound = q1 - 1.5 * IQR\n",
    "# upper_bound = q3 + 1.5 * IQR\n",
    "\n",
    "# df_no_target_outliers = df_no_null_target[(df_no_null_target['taxvaluedollarcnt'] >= lower_bound) & (df_no_null_target['taxvaluedollarcnt']<= upper_bound)]\n",
    "# print(df_no_target_outliers)\n",
    "# df_no_target_outliers.info()\n",
    "\n",
    "# # mode imputation since categorical variables present\n",
    "\n",
    "# mode_imputed_data = df_no_target_outliers.fillna(df_no_target_outliers.mode().iloc[0])\n",
    "# # print(mode_imputed_data)\n",
    "\n",
    "# df_cleaned = mode_imputed_data\n",
    "# print(df_cleaned)\n",
    "\n",
    "# cleaned_data = pd.DataFrame(df_cleaned)\n",
    "# cleaned_data.to_csv('M1_cleaned_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Baseline Modeling [3 pts]\n",
    "\n",
    "Apply the following regression models to the scaled training dataset using **default parameters**:\n",
    "\n",
    "- Linear Regression\n",
    "- Ridge Regression\n",
    "- Lasso Regression\n",
    "- Decision Tree Regression\n",
    "- Bagging\n",
    "- Random Forest\n",
    "- Gradient Boosting Trees\n",
    "\n",
    "For each model:\n",
    "- Use **repeated cross-validation** (e.g., 5 folds, 5 repeats).\n",
    "- Report the **mean and standard deviation of CV RMSE Score** across all folds in a table. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Discussion [2 pts]\n",
    "\n",
    "In a paragraph or well-organized set of bullet points, briefly compare and discuss:\n",
    "\n",
    "  - Which models perform best overall?\n",
    "  - Which are most stable (lowest std)?\n",
    "  - Any signs of overfitting or underfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Feature Engineering [3 pts]\n",
    "\n",
    "Consider **at least three new features** based on your Milestone 1, Part 5. Examples include:\n",
    "- Polynomial terms\n",
    "- Log or interaction terms\n",
    "- Groupings or transformations of categorical features\n",
    "\n",
    "Add these features to `X_train` and then:\n",
    "- Scale using `StandardScaler` \n",
    "- Re-run all models listed above (using default settings again).\n",
    "- Report updated RMSE scores (mean and std) across repeated CV in a table. \n",
    "\n",
    "**Note:**  Recall that this will require creating a new version of the dataset, so effectively you may be running \"polynomial regression\" using `LinearRegression`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need\n",
    "\n",
    "# from sklearn.preprocessing import StandardScaler, PolynomialFeatures \n",
    "# from sklearn.model_selection import cross_val_score, RepeatedKFold\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "# from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train test split cleaned dataset \n",
    "# X = df_cleaned.drop(columns=['taxvaluedollarcnt']) # Features (all columns except the target)\n",
    "# y = df_cleaned['taxvaluedollarcnt'] # Target variable\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# X_train_num = X_train.select_dtypes(include=['float64', 'int64'])\n",
    "# X_test_num = X_test.select_dtypes(include=['float64', 'int64'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: Polynomial Features \n",
    "\n",
    "# #setup poly \n",
    "# poly = PolynomialFeatures(degree=2, include_bias=False, interaction_only=True)\n",
    "# X_train_poly = poly.fit_transform(X_train_num)\n",
    "# X_test_poly = poly.transform(X_test_num)\n",
    "\n",
    "# feature_names_poly = poly.get_feature_names_out(X_train_num.columns)\n",
    "# print(feature_names_poly)\n",
    "# #train values on poly \n",
    "# X_train_poly_df_cleaned = pd.DataFrame(X_train_poly, columns=feature_names_poly, index=X_train.index)\n",
    "# X_test_poly_df_cleaned = pd.DataFrame(X_test_poly, columns=feature_names_poly, index=X_test.index)\n",
    "# #print(X_train_poly_df_cleaned)\n",
    "\n",
    "# #scale  \n",
    "# scaler = StandardScaler()\n",
    "# X_train_poly_scaled = scaler.fit_transform(X_train_poly_df_cleaned)\n",
    "# X_test_poly_scaled = scaler.transform(X_test_poly_df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1 Modeling: \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature 2: Logarithmic Features \n",
    "\n",
    "# #setup log\n",
    "# X_train_log = np.log1p(X_train_num)\n",
    "# X_test_log = np.log1p(X_test_num)\n",
    "\n",
    "# X_train_log.columns = [f'log_{col}' for col in X_train_log.columns]\n",
    "# X_test_log.columns = [f'log_{col}' for col in X_test_log.columns]\n",
    "\n",
    "# #scale \n",
    "# scaler = StandardScaler()\n",
    "# X_train_log_scaled = scaler.fit_transform(X_train_log)\n",
    "# X_test_log_scaled = scaler.fit_transform(X_test_log)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2 Modeling: \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def target_encoding(df_cleaned, target_col='taxvaluedollarcnt'):\n",
    "#     encoding = df_cleaned.groupby([target_col]).mean()\n",
    "#     df_cleaned[+ '_encoded'] = df_cleaned[].map(encoding)\n",
    "#     return df_cleaned\n",
    "\n",
    "# X_train_target = target_encoding(X_train, 'categorical_column', 'target_column')\n",
    "# X_test_target = target_encoding(X_test, 'category_column', 'target_column')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df_cleaned.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Normalization \n",
    "\n",
    "# #setup Normalization\n",
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# X = df_cleaned.drop(columns=['taxvaluedollarcnt'])\n",
    "# y = df_cleaned['taxvaluedollarcnt']\n",
    "\n",
    "# scaler = MinMaxScaler()\n",
    "# X_train_normalized = scaler.fit_transform(X_train)\n",
    "# X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# X_train_normalized_df = pd.DataFrame(X_train_normalized, columns=X.columns)\n",
    "# X_test_normalized_df = pd.DataFrame(X_test_normalized, columns=X.columns)\n",
    "# print(X_train_normalized_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_poly_df_cleaned.reset_index(drop=True, inplace=True)\n",
    "# X_train_log.reset_index(drop=True, inplace=True)\n",
    "# X_train_normalized_df.reset_index(drop=True, inplace=True)\n",
    "# X_train.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Feature 3: Target Encoding \n",
    "\n",
    "# #setup Target Encoding \n",
    "\n",
    "# def target_encoding(df_cleaned, target_col='taxvaluedollarcnt'):\n",
    "    \n",
    "#     if target_col not in df_cleaned.columns:\n",
    "#         raise KeyError(f\"Target column '{target_col}' not found in the DataFrame.\")\n",
    "    \n",
    "#     X = df_cleaned.drop(columns=[target_col])\n",
    "#     y = df_cleaned[target_col]\n",
    "\n",
    "#     categorical_cols = X.select_dtypes(include=['object']).columns \n",
    "#     for col in categorical_cols:\n",
    "#         encoding = df_cleaned.groupby(col)[target_col].mean()\n",
    "#         X[col + '_encoded'] = X[col].map(encoding)\n",
    "    \n",
    "#     print(\"Target Encoding applied:\")\n",
    "#     print(X.head())\n",
    "#     return X\n",
    "\n",
    "# X_train_target_enc = target_encoding(X_train, target_col='taxvaluedollarcnt')\n",
    "# X_test_target_enc = target_encoding(X_test, target_col='taxvaluedollarcnt')\n",
    "# # \n",
    "# # \n",
    "# # #df_cleaned_target_encoded = target_encoding(df_cleaned)\n",
    "# # #df_sample_target_encoded = df_cleaned_target_encoded.sample(n=1000, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_sample = X_train.sample(n=1000, random_state=42)\n",
    "\n",
    "# X_train_combined = pd.concat([\n",
    "#     X_train_sample, \n",
    "#     X_train_poly_df_cleaned, \n",
    "#     X_train_log, \n",
    "#     X_train_normalized_df\n",
    "# ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(X_train_combined)\n",
    "# X_train_combined_ = X_train_combined.dropna()\n",
    "# print(X_train_combined_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scale using Standard Scaler \n",
    "\n",
    "# scale = StandardScaler()\n",
    "# X_train_scaled = scale.fit_transform(X_train_combined)\n",
    "\n",
    "# X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X_train_combined.columns)\n",
    "\n",
    "# print(X_train_scaled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# X_train_combined = np.hstack([X_train_poly_df_cleaned, X_train_log, X_train_normalized_df])\n",
    "# print(X_train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X_trained_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Part 2 Models \n",
    "# from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "# from sklearn.model_selection import cross_val_score, KFold\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# # Linear Regression \n",
    "\n",
    "# models = {\n",
    "#     'Linear Regression': LinearRegression(), \n",
    "#     'Ridge Regression': Ridge(), \n",
    "#     'Lasso Regression': Lasso(), \n",
    "#     'Decision Tree Regressor': DecisionTreeRegressor(), \n",
    "#     'Bagging Regressor': BaggingRegressor(), \n",
    "#     'Random Forest Regressor': RandomForestRegressor()\n",
    "# }\n",
    "\n",
    "# kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "# cv_results = []\n",
    "\n",
    "# for model_name, model in models.items():\n",
    "#     neg_mse_scores = cross_val_score(model, X_train_combined, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "#     rmse_scores = np.sqrt(-neg_mse_scores)\n",
    "#     cv_results.append({\n",
    "#         'Model': model_name, \n",
    "#         'Mean RMSE': np.mean(rmse_scores), \n",
    "#         'Std RMSE': np.std(rmse_scores)\n",
    "#     })\n",
    "\n",
    "# cv_results_df_cleaned = pd.DataFrame(cv_results)\n",
    "# print(cv_results_df_cleaned)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is the correct one: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       airconditioningtypeid  architecturalstyletypeid   bathroomcnt  \\\n",
      "count           77613.000000              77613.000000  77613.000000   \n",
      "mean                1.812013                  7.386473      2.298496   \n",
      "std                 1.683429                  0.140546      0.996513   \n",
      "min                 1.000000                  2.000000      0.000000   \n",
      "25%                 1.000000                  7.386473      2.000000   \n",
      "50%                 1.812013                  7.386473      2.000000   \n",
      "75%                 1.812013                  7.386473      3.000000   \n",
      "max                13.000000                 21.000000     18.000000   \n",
      "\n",
      "         bedroomcnt  buildingclasstypeid  buildingqualitytypeid  \\\n",
      "count  77613.000000         77613.000000           77613.000000   \n",
      "mean       3.053223             3.933333               6.533779   \n",
      "std        1.140230             0.003468               1.379538   \n",
      "min        0.000000             3.000000               1.000000   \n",
      "25%        2.000000             3.933333               6.000000   \n",
      "50%        3.000000             3.933333               6.533779   \n",
      "75%        4.000000             3.933333               7.000000   \n",
      "max       16.000000             4.000000              12.000000   \n",
      "\n",
      "       calculatedbathnbr  decktypeid  finishedfloor1squarefeet  \\\n",
      "count       77613.000000     77613.0              77613.000000   \n",
      "mean            2.316392        66.0               1366.165314   \n",
      "std             0.975578         0.0                187.042091   \n",
      "min             1.000000        66.0                 44.000000   \n",
      "25%             2.000000        66.0               1366.165314   \n",
      "50%             2.000000        66.0               1366.165314   \n",
      "75%             3.000000        66.0               1366.165314   \n",
      "max            18.000000        66.0               6912.000000   \n",
      "\n",
      "       calculatedfinishedsquarefeet  ...  numberofstories  assessmentyear  \\\n",
      "count                  77613.000000  ...     77613.000000         77613.0   \n",
      "mean                    1784.935421  ...         1.434286          2016.0   \n",
      "std                      952.804598  ...         0.259285             0.0   \n",
      "min                      128.000000  ...         1.000000          2016.0   \n",
      "25%                     1184.000000  ...         1.434286          2016.0   \n",
      "50%                     1546.000000  ...         1.434286          2016.0   \n",
      "75%                     2109.000000  ...         1.434286          2016.0   \n",
      "max                    35640.000000  ...         6.000000          2016.0   \n",
      "\n",
      "       taxdelinquencyyear  taxvaluedollarcnt  mean_propertycountylandusecode  \\\n",
      "count        77613.000000       7.761300e+04                    7.761300e+04   \n",
      "mean            14.088276       4.901506e+05                    4.901506e+05   \n",
      "std              0.421572       6.536504e+05                    1.892402e+05   \n",
      "min              3.000000       1.000000e+03                    1.450000e+05   \n",
      "25%             14.088276       2.069250e+05                    4.021687e+05   \n",
      "50%             14.088276       3.589710e+05                    4.043582e+05   \n",
      "75%             14.088276       5.688620e+05                    5.588589e+05   \n",
      "max             99.000000       4.906124e+07                    8.068454e+06   \n",
      "\n",
      "       mean_propertyzoningdesc  hashottuborspa_True  hashottuborspa_Missing  \\\n",
      "count             7.761300e+04         77613.000000            77613.000000   \n",
      "mean              4.901506e+05             0.019829                0.980171   \n",
      "std               2.877158e+05             0.139414                0.139414   \n",
      "min               3.101800e+04             0.000000                0.000000   \n",
      "25%               3.565037e+05             0.000000                1.000000   \n",
      "50%               5.238313e+05             0.000000                1.000000   \n",
      "75%               5.238313e+05             0.000000                1.000000   \n",
      "max               9.324332e+06             1.000000                1.000000   \n",
      "\n",
      "       taxdelinquencyflag_Missing  taxdelinquencyflag_Y  \n",
      "count                77613.000000          77613.000000  \n",
      "mean                     0.962635              0.037365  \n",
      "std                      0.189655              0.189655  \n",
      "min                      0.000000              0.000000  \n",
      "25%                      1.000000              0.000000  \n",
      "50%                      1.000000              0.000000  \n",
      "75%                      1.000000              0.000000  \n",
      "max                      1.000000              1.000000  \n",
      "\n",
      "[8 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77613 entries, 0 to 77612\n",
      "Data columns (total 50 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   airconditioningtypeid           77613 non-null  float64\n",
      " 1   architecturalstyletypeid        77613 non-null  float64\n",
      " 2   bathroomcnt                     77613 non-null  float64\n",
      " 3   bedroomcnt                      77613 non-null  float64\n",
      " 4   buildingclasstypeid             77613 non-null  float64\n",
      " 5   buildingqualitytypeid           77613 non-null  float64\n",
      " 6   calculatedbathnbr               77613 non-null  float64\n",
      " 7   decktypeid                      77613 non-null  float64\n",
      " 8   finishedfloor1squarefeet        77613 non-null  float64\n",
      " 9   calculatedfinishedsquarefeet    77613 non-null  float64\n",
      " 10  finishedsquarefeet12            77613 non-null  float64\n",
      " 11  finishedsquarefeet13            77613 non-null  float64\n",
      " 12  finishedsquarefeet15            77613 non-null  float64\n",
      " 13  finishedsquarefeet50            77613 non-null  float64\n",
      " 14  finishedsquarefeet6             77613 non-null  float64\n",
      " 15  fips                            77613 non-null  float64\n",
      " 16  fullbathcnt                     77613 non-null  float64\n",
      " 17  garagecarcnt                    77613 non-null  float64\n",
      " 18  garagetotalsqft                 77613 non-null  float64\n",
      " 19  heatingorsystemtypeid           77613 non-null  float64\n",
      " 20  latitude                        77613 non-null  float64\n",
      " 21  longitude                       77613 non-null  float64\n",
      " 22  lotsizesquarefeet               77613 non-null  float64\n",
      " 23  poolcnt                         77613 non-null  float64\n",
      " 24  poolsizesum                     77613 non-null  float64\n",
      " 25  pooltypeid10                    77613 non-null  float64\n",
      " 26  pooltypeid2                     77613 non-null  float64\n",
      " 27  pooltypeid7                     77613 non-null  float64\n",
      " 28  propertylandusetypeid           77613 non-null  float64\n",
      " 29  rawcensustractandblock          77613 non-null  float64\n",
      " 30  regionidcity                    77613 non-null  float64\n",
      " 31  regionidcounty                  77613 non-null  float64\n",
      " 32  regionidneighborhood            77613 non-null  float64\n",
      " 33  regionidzip                     77613 non-null  float64\n",
      " 34  roomcnt                         77613 non-null  float64\n",
      " 35  threequarterbathnbr             77613 non-null  float64\n",
      " 36  typeconstructiontypeid          77613 non-null  float64\n",
      " 37  unitcnt                         77613 non-null  float64\n",
      " 38  yardbuildingsqft26              77613 non-null  float64\n",
      " 39  yearbuilt                       77613 non-null  float64\n",
      " 40  numberofstories                 77613 non-null  float64\n",
      " 41  assessmentyear                  77613 non-null  float64\n",
      " 42  taxdelinquencyyear              77613 non-null  float64\n",
      " 43  taxvaluedollarcnt               77613 non-null  float64\n",
      " 44  mean_propertycountylandusecode  77613 non-null  float64\n",
      " 45  mean_propertyzoningdesc         77613 non-null  float64\n",
      " 46  hashottuborspa_True             77613 non-null  int64  \n",
      " 47  hashottuborspa_Missing          77613 non-null  int64  \n",
      " 48  taxdelinquencyflag_Missing      77613 non-null  int64  \n",
      " 49  taxdelinquencyflag_Y            77613 non-null  int64  \n",
      "dtypes: float64(46), int64(4)\n",
      "memory usage: 29.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df_cleaned = pd.read_csv('zillow_cleaned.csv')\n",
    "print(df_cleaned.describe())\n",
    "print(df_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# variable setup \n",
    "target_col = 'taxvaluedollarcnt'\n",
    "\n",
    "X = df_cleaned.drop(columns=[target_col])\n",
    "y = df_cleaned[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# polynomial feature\n",
    "num_cols = X_train.select_dtypes(include=['float64', 'int64']).columns\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = pd.DataFrame(poly.fit_transform(X_train[num_cols]), columns=poly.get_feature_names_out(num_cols))\n",
    "\n",
    "# log feature\n",
    "log_cols = X_train[num_cols].columns\n",
    "X_train_log = X_train[log_cols].apply(lambda x: np.log1p(x.clip(lower=0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target encoding for categorical variables\n",
    "\n",
    "X_train_target = X_train.select_dtypes(include=['object']).copy()\n",
    "for col in X_train_target.columns:\n",
    "    mean_encoded = df_cleaned.groupby(col)[target_col].mean()\n",
    "    X_train_target[col + '_enc'] = X_train_target[col].map(mean_encoded)\n",
    "X_train_target_enc = X_train_target.drop(columns=X_train_target.select_dtypes(include='object').columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine feature engineering techniques\n",
    "X_train_combined = pd.concat([\n",
    "    X_train.reset_index(drop=True),\n",
    "    X_train_poly.reset_index(drop=True),\n",
    "    X_train_log.reset_index(drop=True),\n",
    "    X_train_target_enc.reset_index(drop=True)\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get rid of replicated columns\n",
    "\n",
    "X_train_combined = X_train_combined.drop(columns=X_train_combined.select_dtypes(include='object').columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale X_train\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.490e+15, tolerance: 1.091e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.883e+15, tolerance: 1.610e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "# set up models to compare RMSE \n",
    "models = {\n",
    "    \"LinearRegression\": LinearRegression(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"DecisionTree\": DecisionTreeRegressor(),\n",
    "    \"Bagging\": BaggingRegressor(),\n",
    "    \"RandomForest\": RandomForestRegressor()\n",
    "}\n",
    "\n",
    "kf = KFold(n_splits=2, shuffle=True, random_state=42)\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    neg_mse = cross_val_score(model, X_train_scaled, y_train, cv=kf, scoring='neg_root_mean_squared_error')\n",
    "    rmse_scores = -neg_mse\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Mean RMSE\": np.mean(rmse_scores)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by=\"Mean RMSE\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Discussion [2 pts]\n",
    "\n",
    "Reflect on the impact of your new features:\n",
    "\n",
    "- Did any models show notable improvement in performance?\n",
    "\n",
    "- Which new features seemed to help — and in which models?\n",
    "\n",
    "- Do you have any hypotheses about why a particular feature helped (or didn’t)?\n",
    "\n",
    "- Were there any unexpected results?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       airconditioningtypeid  architecturalstyletypeid   bathroomcnt  \\\n",
      "count           77613.000000              77613.000000  77613.000000   \n",
      "mean                1.812013                  7.386473      2.298496   \n",
      "std                 1.683429                  0.140546      0.996513   \n",
      "min                 1.000000                  2.000000      0.000000   \n",
      "25%                 1.000000                  7.386473      2.000000   \n",
      "50%                 1.812013                  7.386473      2.000000   \n",
      "75%                 1.812013                  7.386473      3.000000   \n",
      "max                13.000000                 21.000000     18.000000   \n",
      "\n",
      "         bedroomcnt  buildingclasstypeid  buildingqualitytypeid  \\\n",
      "count  77613.000000         77613.000000           77613.000000   \n",
      "mean       3.053223             3.933333               6.533779   \n",
      "std        1.140230             0.003468               1.379538   \n",
      "min        0.000000             3.000000               1.000000   \n",
      "25%        2.000000             3.933333               6.000000   \n",
      "50%        3.000000             3.933333               6.533779   \n",
      "75%        4.000000             3.933333               7.000000   \n",
      "max       16.000000             4.000000              12.000000   \n",
      "\n",
      "       calculatedbathnbr  decktypeid  finishedfloor1squarefeet  \\\n",
      "count       77613.000000     77613.0              77613.000000   \n",
      "mean            2.316392        66.0               1366.165314   \n",
      "std             0.975578         0.0                187.042091   \n",
      "min             1.000000        66.0                 44.000000   \n",
      "25%             2.000000        66.0               1366.165314   \n",
      "50%             2.000000        66.0               1366.165314   \n",
      "75%             3.000000        66.0               1366.165314   \n",
      "max            18.000000        66.0               6912.000000   \n",
      "\n",
      "       calculatedfinishedsquarefeet  ...  numberofstories  assessmentyear  \\\n",
      "count                  77613.000000  ...     77613.000000         77613.0   \n",
      "mean                    1784.935421  ...         1.434286          2016.0   \n",
      "std                      952.804598  ...         0.259285             0.0   \n",
      "min                      128.000000  ...         1.000000          2016.0   \n",
      "25%                     1184.000000  ...         1.434286          2016.0   \n",
      "50%                     1546.000000  ...         1.434286          2016.0   \n",
      "75%                     2109.000000  ...         1.434286          2016.0   \n",
      "max                    35640.000000  ...         6.000000          2016.0   \n",
      "\n",
      "       taxdelinquencyyear  taxvaluedollarcnt  mean_propertycountylandusecode  \\\n",
      "count        77613.000000       7.761300e+04                    7.761300e+04   \n",
      "mean            14.088276       4.901506e+05                    4.901506e+05   \n",
      "std              0.421572       6.536504e+05                    1.892402e+05   \n",
      "min              3.000000       1.000000e+03                    1.450000e+05   \n",
      "25%             14.088276       2.069250e+05                    4.021687e+05   \n",
      "50%             14.088276       3.589710e+05                    4.043582e+05   \n",
      "75%             14.088276       5.688620e+05                    5.588589e+05   \n",
      "max             99.000000       4.906124e+07                    8.068454e+06   \n",
      "\n",
      "       mean_propertyzoningdesc  hashottuborspa_True  hashottuborspa_Missing  \\\n",
      "count             7.761300e+04         77613.000000            77613.000000   \n",
      "mean              4.901506e+05             0.019829                0.980171   \n",
      "std               2.877158e+05             0.139414                0.139414   \n",
      "min               3.101800e+04             0.000000                0.000000   \n",
      "25%               3.565037e+05             0.000000                1.000000   \n",
      "50%               5.238313e+05             0.000000                1.000000   \n",
      "75%               5.238313e+05             0.000000                1.000000   \n",
      "max               9.324332e+06             1.000000                1.000000   \n",
      "\n",
      "       taxdelinquencyflag_Missing  taxdelinquencyflag_Y  \n",
      "count                77613.000000          77613.000000  \n",
      "mean                     0.962635              0.037365  \n",
      "std                      0.189655              0.189655  \n",
      "min                      0.000000              0.000000  \n",
      "25%                      1.000000              0.000000  \n",
      "50%                      1.000000              0.000000  \n",
      "75%                      1.000000              0.000000  \n",
      "max                      1.000000              1.000000  \n",
      "\n",
      "[8 rows x 50 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 77613 entries, 0 to 77612\n",
      "Data columns (total 50 columns):\n",
      " #   Column                          Non-Null Count  Dtype  \n",
      "---  ------                          --------------  -----  \n",
      " 0   airconditioningtypeid           77613 non-null  float64\n",
      " 1   architecturalstyletypeid        77613 non-null  float64\n",
      " 2   bathroomcnt                     77613 non-null  float64\n",
      " 3   bedroomcnt                      77613 non-null  float64\n",
      " 4   buildingclasstypeid             77613 non-null  float64\n",
      " 5   buildingqualitytypeid           77613 non-null  float64\n",
      " 6   calculatedbathnbr               77613 non-null  float64\n",
      " 7   decktypeid                      77613 non-null  float64\n",
      " 8   finishedfloor1squarefeet        77613 non-null  float64\n",
      " 9   calculatedfinishedsquarefeet    77613 non-null  float64\n",
      " 10  finishedsquarefeet12            77613 non-null  float64\n",
      " 11  finishedsquarefeet13            77613 non-null  float64\n",
      " 12  finishedsquarefeet15            77613 non-null  float64\n",
      " 13  finishedsquarefeet50            77613 non-null  float64\n",
      " 14  finishedsquarefeet6             77613 non-null  float64\n",
      " 15  fips                            77613 non-null  float64\n",
      " 16  fullbathcnt                     77613 non-null  float64\n",
      " 17  garagecarcnt                    77613 non-null  float64\n",
      " 18  garagetotalsqft                 77613 non-null  float64\n",
      " 19  heatingorsystemtypeid           77613 non-null  float64\n",
      " 20  latitude                        77613 non-null  float64\n",
      " 21  longitude                       77613 non-null  float64\n",
      " 22  lotsizesquarefeet               77613 non-null  float64\n",
      " 23  poolcnt                         77613 non-null  float64\n",
      " 24  poolsizesum                     77613 non-null  float64\n",
      " 25  pooltypeid10                    77613 non-null  float64\n",
      " 26  pooltypeid2                     77613 non-null  float64\n",
      " 27  pooltypeid7                     77613 non-null  float64\n",
      " 28  propertylandusetypeid           77613 non-null  float64\n",
      " 29  rawcensustractandblock          77613 non-null  float64\n",
      " 30  regionidcity                    77613 non-null  float64\n",
      " 31  regionidcounty                  77613 non-null  float64\n",
      " 32  regionidneighborhood            77613 non-null  float64\n",
      " 33  regionidzip                     77613 non-null  float64\n",
      " 34  roomcnt                         77613 non-null  float64\n",
      " 35  threequarterbathnbr             77613 non-null  float64\n",
      " 36  typeconstructiontypeid          77613 non-null  float64\n",
      " 37  unitcnt                         77613 non-null  float64\n",
      " 38  yardbuildingsqft26              77613 non-null  float64\n",
      " 39  yearbuilt                       77613 non-null  float64\n",
      " 40  numberofstories                 77613 non-null  float64\n",
      " 41  assessmentyear                  77613 non-null  float64\n",
      " 42  taxdelinquencyyear              77613 non-null  float64\n",
      " 43  taxvaluedollarcnt               77613 non-null  float64\n",
      " 44  mean_propertycountylandusecode  77613 non-null  float64\n",
      " 45  mean_propertyzoningdesc         77613 non-null  float64\n",
      " 46  hashottuborspa_True             77613 non-null  int64  \n",
      " 47  hashottuborspa_Missing          77613 non-null  int64  \n",
      " 48  taxdelinquencyflag_Missing      77613 non-null  int64  \n",
      " 49  taxdelinquencyflag_Y            77613 non-null  int64  \n",
      "dtypes: float64(46), int64(4)\n",
      "memory usage: 29.6 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.124e+15, tolerance: 1.843e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.532e+15, tolerance: 2.206e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.595e+15, tolerance: 2.190e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "/home/codespace/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 4.518e+15, tolerance: 2.259e+12\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     14\u001b[39m results = []\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m name, model \u001b[38;5;129;01min\u001b[39;00m models.items():\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     neg_mse = \u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train_scaled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_root_mean_squared_error\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m     rmse_scores = -neg_mse\n\u001b[32m     19\u001b[39m     results.append({\n\u001b[32m     20\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mModel\u001b[39m\u001b[33m\"\u001b[39m: name,\n\u001b[32m     21\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMean RMSE\u001b[39m\u001b[33m\"\u001b[39m: np.mean(rmse_scores),\n\u001b[32m     22\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mStd RMSE\u001b[39m\u001b[33m\"\u001b[39m: np.std(rmse_scores)\n\u001b[32m     23\u001b[39m     })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:866\u001b[39m, in \u001b[36m_fit_and_score\u001b[39m\u001b[34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[39m\n\u001b[32m    864\u001b[39m         estimator.fit(X_train, **fit_params)\n\u001b[32m    865\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m866\u001b[39m         \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Note fit time as time until error\u001b[39;00m\n\u001b[32m    870\u001b[39m     fit_time = time.time() - start_time\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:1080\u001b[39m, in \u001b[36mElasticNet.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1079\u001b[39m     this_Xy = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1080\u001b[39m _, this_coef, this_dual_gap, this_iter = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1081\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1083\u001b[39m \u001b[43m    \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1084\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1085\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_alphas\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1086\u001b[39m \u001b[43m    \u001b[49m\u001b[43malphas\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43malpha\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1087\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprecompute\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprecompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1088\u001b[39m \u001b[43m    \u001b[49m\u001b[43mXy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthis_Xy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1089\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy_X\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_n_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1093\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpositive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1094\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# from here on **params\u001b[39;49;00m\n\u001b[32m   1096\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1097\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1098\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_scale\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1099\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1100\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1101\u001b[39m \u001b[43m    \u001b[49m\u001b[43mselection\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mselection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1102\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1103\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1104\u001b[39m coef_[k] = this_coef[:, \u001b[32m0\u001b[39m]\n\u001b[32m   1105\u001b[39m dual_gaps_[k] = this_dual_gap[\u001b[32m0\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/linear_model/_coordinate_descent.py:695\u001b[39m, in \u001b[36menet_path\u001b[39m\u001b[34m(X, y, l1_ratio, eps, n_alphas, alphas, precompute, Xy, copy_X, coef_init, verbose, return_n_iter, positive, check_input, **params)\u001b[39m\n\u001b[32m    681\u001b[39m     model = cd_fast.enet_coordinate_descent_gram(\n\u001b[32m    682\u001b[39m         coef_,\n\u001b[32m    683\u001b[39m         l1_reg,\n\u001b[32m   (...)\u001b[39m\u001b[32m    692\u001b[39m         positive,\n\u001b[32m    693\u001b[39m     )\n\u001b[32m    694\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m precompute \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m695\u001b[39m     model = \u001b[43mcd_fast\u001b[49m\u001b[43m.\u001b[49m\u001b[43menet_coordinate_descent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcoef_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml1_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml2_reg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpositive\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    698\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    700\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mPrecompute should be one of True, False, \u001b[39m\u001b[33m'\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or array-like. Got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    701\u001b[39m         % precompute\n\u001b[32m    702\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m_cd_fast.pyx:257\u001b[39m, in \u001b[36msklearn.linear_model._cd_fast.enet_coordinate_descent\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/numpy/_core/getlimits.py:493\u001b[39m, in \u001b[36mfinfo.__new__\u001b[39m\u001b[34m(cls, dtype)\u001b[39m\n\u001b[32m    489\u001b[39m _finfo_cache = {}\n\u001b[32m    491\u001b[39m __class_getitem__ = \u001b[38;5;28mclassmethod\u001b[39m(types.GenericAlias)\n\u001b[32m--> \u001b[39m\u001b[32m493\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, dtype):\n\u001b[32m    494\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    495\u001b[39m         obj = \u001b[38;5;28mcls\u001b[39m._finfo_cache.get(dtype)  \u001b[38;5;66;03m# most common path\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Feature Selection [3 pts]\n",
    "\n",
    "Using the full set of features (original + engineered):\n",
    "- Apply **feature selection** methods to investigate whether you can improve performance.\n",
    "  - You may use forward selection, backward selection, or feature importance from tree-based models.\n",
    "- For each model, identify the **best-performing subset of features**.\n",
    "- Re-run each model using only those features.\n",
    "- Report updated RMSE scores (mean and std) across repeated CV in a table.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Discussion [2 pts]\n",
    "\n",
    "Analyze the effect of feature selection on your models:\n",
    "\n",
    "- Did performance improve for any models after reducing the number of features?\n",
    "\n",
    "- Which features were consistently retained across models?\n",
    "\n",
    "- Were any of your newly engineered features selected as important?\n",
    "\n",
    "- How did feature selection differ between linear and tree-based models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Fine-Tuning Your Top 3 Models [6 pts]\n",
    "\n",
    "In this final phase of Milestone 2, you’ll select and refine your **three most promising models and their corresponding data pipelines** based on everything you've done so far.\n",
    "\n",
    "1. Choose the top 3 models based on performance and interpretability from earlier parts.\n",
    "2. For each model:\n",
    "   - Perform hyperparameter tuning using `sweep_parameters`, `GridSearchCV`, `RandomizedSearchCV`, or other techniques from previous homeworks. \n",
    "   - Experiment with different versions of your feature engineering and preprocessing — treat these as additional tunable components.\n",
    "3. Report the mean and standard deviation of CV RMSE score for each model in a summary table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add as many code cells as you need"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Discussion [4 pts]\n",
    "\n",
    "Reflect on your tuning process and final results:\n",
    "\n",
    "- What was your tuning strategy for each model? Why did you choose those hyperparameters?\n",
    "- Did you find that certain types of preprocessing or feature engineering worked better with specific models?\n",
    "- Provide a ranking of your three models and explain your reasoning — not just based on RMSE, but also interpretability, training time, or generalizability.\n",
    "- Conclude by considering whether this workflow has produced the results you expected. Typically, you would repeat steps 2 - 4 and also reconsider the choices you made in Milestone 1 when cleaning the dataset, until reaching the point of diminishing returns; do you think that would that have helped here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Your text here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
